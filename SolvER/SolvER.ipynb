{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "becf306a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24c5e933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEBUG= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62e3c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/root/workspace/FAISS-Imputation/GITHUB/SolvER/data/DBLP-ACM/\"\n",
    "DATA_PATH_FOR_MATCHER=\"/DBLP-ACM\"\n",
    "CONFIG_PATH = \"/root/workspace/FAISS-Imputation/GITHUB/SolvER/configs.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5452b4b2",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "183f7f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_again_from_scratch():\n",
    "  os.system(\"CUDA_VISIBLE_DEVICES=0 python train_ditto.py --task \" +str(DATA_PATH_FOR_MATCHER)+\" --batch_size 32 --max_len 64 --lr 3e-5 --n_epochs 15 --finetuning  --lm distilbert  --fp16  --save_model  --da drop_col\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfedfe7d",
   "metadata": {},
   "source": [
    "# Run the matche\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "acf17e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_values(s):\n",
    "    load_f1_pattern = re.compile(r'load_f1\\s*=\\s*([0-9.]+)')\n",
    "    real_f1_pattern = re.compile(r'real_f1\\s*=\\s*([0-9.]+)')\n",
    "    tn_pattern = re.compile(r'TN\\s*=\\s*([0-9.]+)')\n",
    "    tp_pattern = re.compile(r'TP\\s*=\\s*([0-9.]+)')\n",
    "    fn_pattern = re.compile(r'FN\\s*=\\s*([0-9.]+)')\n",
    "    fp_pattern = re.compile(r'FP\\s*=\\s*([0-9.]+)')\n",
    "    fnr_pattern = re.compile(r'FNR\\s*=\\s*([0-9.]+)')\n",
    "    rec_pattern = re.compile(r'REC\\s*=\\s*([0-9.]+)')\n",
    "\n",
    "    load_f1_match = load_f1_pattern.search(s)\n",
    "    real_f1_match = real_f1_pattern.search(s)\n",
    "    tn_match = tn_pattern.search(s)\n",
    "    tp_match = tp_pattern.search(s)\n",
    "    fn_match = fn_pattern.search(s)\n",
    "    fp_match = fp_pattern.search(s)\n",
    "    fnr_match = fnr_pattern.search(s)\n",
    "    rec_match = rec_pattern.search(s)\n",
    "    if load_f1_match:\n",
    "        load_f1_value = float(load_f1_match.group(1))\n",
    "    else:\n",
    "        load_f1_value = -1\n",
    "    if real_f1_match:\n",
    "        real_f1_value = float(real_f1_match.group(1))\n",
    "    else:\n",
    "        real_f1_value = -1\n",
    "    if tn_match:\n",
    "        tn_value = float(tn_match.group(1))\n",
    "    else:\n",
    "        tn_value = -1\n",
    "    if tp_match:\n",
    "        tp_value = float(tp_match.group(1))\n",
    "    else:\n",
    "        tp_value = -1\n",
    "    if fn_match:\n",
    "        fn_value = float(fn_match.group(1))\n",
    "    else:\n",
    "        fn_value = -1\n",
    "    if fp_match:\n",
    "        fp_value = float(fp_match.group(1))\n",
    "    else:\n",
    "        fp_value = -1\n",
    "    if fnr_match:\n",
    "        fnr_value = float(fnr_match.group(1))\n",
    "    else:\n",
    "        fnr_value = -1\n",
    "    if rec_match:\n",
    "        rec_value = float(rec_match.group(1))\n",
    "    else:\n",
    "        rec_value = -1\n",
    "    return load_f1_value, real_f1_value, tn_value, tp_value, fn_value, fp_value, fnr_value, rec_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15e239b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_matcher(file, out_file):\n",
    "  command = ['python', 'matcher.py', '--task', DATA_PATH_FOR_MATCHER, '--input_path', file, '--output_path',\n",
    "             f'output/{out_file}.jsonl', '--lm', 'distilbert', '--max_len', '64', '--fp16', '--use_gpu', '--checkpoint_path', 'checkpoints/']\n",
    "  result = subprocess.run(command, capture_output=True, text=True)\n",
    "  if DEBUG:\n",
    "    print(result.stdout)\n",
    "    print(result.stderr)\n",
    "  load_f1, real_f1, tn, tp, fn, fp, fnr, rec = get_f1_values(result.stdout)\n",
    "  file_last=file.split('/')[-1]\n",
    "  isImputed=1\n",
    "  if \"nonimputed\" in file_last:\n",
    "    isImputed=0\n",
    "    file_last = file_last.replace(\"_nonimputed_final\",\"\")\n",
    "  else:\n",
    "    file_last = file_last.replace(\"_imputed_final\",\"\")\n",
    "  file=file[:file.rfind('/')+1]+file_last\n",
    "  seed=file_last.split(\"_\")[3][:-4]\n",
    "  subset = file_last.split(\"_\")[2]\n",
    "  return (file, subset, seed, isImputed, real_f1, tn, tp, fn, fp, fnr, rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb4ba67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_config(config_path, data_path, file):\n",
    "    with open(config_path, 'r') as cfg:\n",
    "        config = json.load(cfg)\n",
    "        config[0]['name'] = DATA_PATH_FOR_MATCHER            \n",
    "        config[0]['testset'] = data_path + file\n",
    "        config[0]['trainset'] = \"/root/workspace/FAISS-Imputation/GITHUB/SolvER/data/DBLP-ACM/train_DBLPACMS.txt\"\n",
    "        config[0]['validset'] = \"/root/workspace/FAISS-Imputation/GITHUB/SolvER/data/DBLP-ACM/valid_DBLPACMS.txt\"\n",
    "    with open(config_path, 'w') as cfg_out:\n",
    "        json.dump(config, cfg_out, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ab3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change on-the-fly the configs.json file\n",
    "all_files = os.listdir(DATA_PATH)\n",
    "txt_files = [f for f in all_files if f.endswith(\".txt\")]\n",
    "results = []\n",
    "seeds= 98, 409, 1753, 8424, 2782, 6004, 3581, 5553, 4721, 7179\n",
    "all_percentages=[\"0.0\", \"0.1\", \"0.2\", \"0.3\", \"0.4\"]\n",
    "percentages=all_percentages\n",
    "c=len(txt_files)\n",
    "update_config(CONFIG_PATH, DATA_PATH, \"testing_file_0.0_98_imputed_final.txt\")\n",
    "train_again_from_scratch()\n",
    "for s in seeds:\n",
    "    for p in percentages:\n",
    "        for file in tqdm(txt_files):\n",
    "            if (str(s) in file) and ((str(p)+'_') in file) and (\"testing_\" in file): \n",
    "                print(\"Updating config for \", file)\n",
    "                update_config(CONFIG_PATH, DATA_PATH, file)\n",
    "                name_out = \"output_\"+file\n",
    "                print(\"Processing \", file)\n",
    "                results.append(call_matcher(file=DATA_PATH+file, out_file=name_out))\n",
    "                c=c-1\n",
    "                print(\"REMAINING FILES=\"+str(c))\n",
    "df = pd.DataFrame(results, columns=['file', 'subset', 'seed', 'isImputed', 'real_f1', 'tn','tp', 'fn', 'fp', 'fnr', 'rec'])\n",
    "print(df.head())\n",
    "df.to_csv(f\"{DATA_PATH}/Results_DBLPACM.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tariq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
